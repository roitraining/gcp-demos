{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# **Vertex AI SDK: AutoML tabular forecasting model for batch prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## ðŸ”§ **Setting up**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### 1. Open the notebook\n",
        "\n",
        "[Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Froitraining%2Fgcp-demos%2Frefs%2Fheads%2Fmaster%2Fai%2Fautoml%2Fautoml_forecasting.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V1r4ppTDGpn"
      },
      "source": [
        "### 2. Install packages, set values, create a bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_aip:mbsdk"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_project_id"
      },
      "outputs": [],
      "source": [
        "# Initialize constants and variables\n",
        "# replace <project-id> with your project info\n",
        "PROJECT_ID = \"<project-id>\"\n",
        "LOCATION = \"us-central1\"\n",
        "BUCKET_URI = f\"gs://{PROJECT_ID}-automl\"\n",
        "MODEL_DISPLAY_NAME = \"iowa-liquor-sales-forecast-model\"\n",
        "\n",
        "time_column = \"date\"\n",
        "time_series_identifier_column = \"store_name\"\n",
        "target_column = \"sale_dollars\"\n",
        "\n",
        "COLUMN_SPECS = {\n",
        "    time_column: \"timestamp\",\n",
        "    target_column: \"numeric\",\n",
        "    \"city\": \"categorical\",\n",
        "    \"zip_code\": \"categorical\",\n",
        "    \"county\": \"categorical\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bucket"
      },
      "outputs": [],
      "source": [
        "# set the default project for Google Cloud SDK\n",
        "! gcloud config set project {PROJECT_ID}\n",
        "\n",
        "# Create the Cloud Storage bucket\n",
        "# You can ignore the error reported if the bucket already exists\n",
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26gcoW7yH5DJ"
      },
      "outputs": [],
      "source": [
        "# import libraries and initialize connection to aiplatform\n",
        "import urllib\n",
        "\n",
        "from google.cloud import aiplatform, aiplatform_v1, bigquery\n",
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c9d935c6ab9"
      },
      "outputs": [],
      "source": [
        "# set up for BigQuery actions\n",
        "batch_predict_bq_output_dataset_name = \"iowa_liquor_sales_predictions\"\n",
        "batch_predict_bq_output_dataset_path = \"{}.{}\".format(\n",
        "PROJECT_ID, batch_predict_bq_output_dataset_name\n",
        ")\n",
        "\n",
        "batch_predict_bq_output_uri_prefix = \"bq://{}.{}\".format(\n",
        "    PROJECT_ID, batch_predict_bq_output_dataset_name\n",
        ")\n",
        "\n",
        "TRAINING_DATASET_BQ_PATH = (\n",
        "    \"bq://bigquery-public-data:iowa_liquor_sales_forecasting.2020_sales_train\"\n",
        ")\n",
        "\n",
        "PREDICTION_DATASET_BQ_PATH = (\n",
        "    \"bq://bigquery-public-data:iowa_liquor_sales_forecasting.2021_sales_predict\"\n",
        ")\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create the dataset\n",
        "# skip this if you plan on using existing data from an earlier run\n",
        "bq_dataset_id = bigquery.Dataset(batch_predict_bq_output_dataset_path)\n",
        "dataset_location = \"US\"\n",
        "bq_dataset_id.location = dataset_location\n",
        "\n",
        "\n",
        "try:\n",
        "    client.delete_dataset(bq_dataset_id, delete_contents=True)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "bq_dataset = client.create_dataset(bq_dataset_id)\n",
        "print(\n",
        "    \"Created bigquery dataset {} in {}\".format(\n",
        "        batch_predict_bq_output_dataset_path, dataset_location\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tutorial_start:automl"
      },
      "source": [
        "## **Creating the model**\n",
        "\n",
        "Use this section if you haven't already trained a model. It will take a couple hours to complete the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQV3ZedXM-aw"
      },
      "outputs": [],
      "source": [
        "# create the vertex AI dataset from the data in bigquery\n",
        "dataset = aiplatform.TimeSeriesDataset.create(\n",
        "    display_name=\"iowa_liquor_sales_train\",\n",
        "    bq_source=[TRAINING_DATASET_BQ_PATH],\n",
        ")\n",
        "\n",
        "print(dataset.resource_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE723LtLM-aw"
      },
      "outputs": [],
      "source": [
        "# create the automl training job object\n",
        "training_job = aiplatform.AutoMLForecastingTrainingJob(\n",
        "    display_name=MODEL_DISPLAY_NAME,\n",
        "    optimization_objective=\"minimize-rmse\",\n",
        "    column_specs=COLUMN_SPECS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIuLkHkaM-ax"
      },
      "outputs": [],
      "source": [
        "# run the training job and outpput the model\n",
        "model = training_job.run(\n",
        "    dataset=dataset,\n",
        "    target_column=target_column,\n",
        "    time_column=time_column,\n",
        "    time_series_identifier_column=time_series_identifier_column,\n",
        "    available_at_forecast_columns=[time_column],\n",
        "    unavailable_at_forecast_columns=[target_column],\n",
        "    time_series_attribute_columns=[\"city\", \"zip_code\", \"county\"],\n",
        "    forecast_horizon=30,\n",
        "    context_window=30,\n",
        "    data_granularity_unit=\"day\",\n",
        "    data_granularity_count=1,\n",
        "    weight_column=None,\n",
        "    budget_milli_node_hours=1000,\n",
        "    model_display_name=MODEL_DISPLAY_NAME,\n",
        "    predefined_split_column_name=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6JJxalSIAph"
      },
      "source": [
        "## **Using an existing model**\n",
        "\n",
        "Use this if you've already trained the model per above, and have the model stored in your registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR70-AjsH_Mj"
      },
      "outputs": [],
      "source": [
        "# use the python SDK to create a model object representing the model in the\n",
        "# registry\n",
        "parent = f\"projects/{PROJECT_ID}/locations/{LOCATION}\"\n",
        "api_endpoint = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "model_client = aiplatform_v1.ModelServiceClient(\n",
        "    client_options={\"api_endpoint\": api_endpoint}\n",
        ")\n",
        "\n",
        "target_model = None\n",
        "for model in model_client.list_models(request={\"parent\": parent}):\n",
        "    if model.display_name == MODEL_DISPLAY_NAME:\n",
        "        target_model = model\n",
        "        break\n",
        "if not target_model:\n",
        "    raise RuntimeError(\n",
        "        f\"No model found with display_name '{MODEL_DISPLAY_NAME}' in {parent}\"\n",
        "    )\n",
        "\n",
        "model = aiplatform.Model(model_name=target_model.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "make_prediction"
      },
      "source": [
        "## **Making predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcpKO58xM-a0"
      },
      "outputs": [],
      "source": [
        "# create a batch prediction job with some inputs from bigquery\n",
        "batch_prediction_job = model.batch_predict(\n",
        "    job_display_name=\"iowa_liquor_sales_forecasting_predictions\",\n",
        "    bigquery_source=PREDICTION_DATASET_BQ_PATH,\n",
        "    instances_format=\"bigquery\",\n",
        "    bigquery_destination_prefix=batch_predict_bq_output_uri_prefix,\n",
        "    predictions_format=\"bigquery\",\n",
        "    generate_explanation=True,\n",
        "    sync=False,\n",
        ")\n",
        "\n",
        "print(batch_prediction_job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C202tt-M-a0"
      },
      "outputs": [],
      "source": [
        "# wait for the job to complete. This can take 25+ minutes to complete\n",
        "batch_prediction_job.wait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O57-LbOM-a0"
      },
      "outputs": [],
      "source": [
        "# show the results\n",
        "for row in batch_prediction_job.iter_outputs():\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78080aa9088e"
      },
      "source": [
        "## **Creating a dashboard**\n",
        "\n",
        "Lastly, follow the given link to visualize the generated forecasts in [Data Studio](https://support.google.com/datastudio/answer/6283323?hl=en)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f82f00be2160"
      },
      "outputs": [],
      "source": [
        "tables = client.list_tables(batch_predict_bq_output_dataset_path)\n",
        "\n",
        "prediction_table_id = \"\"\n",
        "for table in tables:\n",
        "    if (\n",
        "        table.table_id.startswith(\"predictions_\")\n",
        "        and table.table_id > prediction_table_id\n",
        "    ):\n",
        "        prediction_table_id = table.table_id\n",
        "batch_predict_bq_output_uri = \"{}.{}\".format(\n",
        "    batch_predict_bq_output_dataset_path, prediction_table_id\n",
        ")\n",
        "\n",
        "\n",
        "def _sanitize_bq_uri(bq_uri):\n",
        "    if bq_uri.startswith(\"bq://\"):\n",
        "        bq_uri = bq_uri[5:]\n",
        "    return bq_uri.replace(\":\", \".\")\n",
        "\n",
        "\n",
        "def get_data_studio_link(\n",
        "    batch_prediction_bq_input_uri,\n",
        "    batch_prediction_bq_output_uri,\n",
        "    time_column,\n",
        "    time_series_identifier_column,\n",
        "    target_column,\n",
        "):\n",
        "    batch_prediction_bq_input_uri = _sanitize_bq_uri(batch_prediction_bq_input_uri)\n",
        "    batch_prediction_bq_output_uri = _sanitize_bq_uri(batch_prediction_bq_output_uri)\n",
        "    base_url = \"https://datastudio.google.com/c/u/0/reporting\"\n",
        "    query = (\n",
        "        \"SELECT \\\\n\"\n",
        "        \" CAST(input.{} as DATETIME) timestamp_col,\\\\n\"\n",
        "        \" CAST(input.{} as STRING) time_series_identifier_col,\\\\n\"\n",
        "        \" CAST(input.{} as NUMERIC) historical_values,\\\\n\"\n",
        "        \" CAST(predicted_{}.value as NUMERIC) predicted_values,\\\\n\"\n",
        "        \" * \\\\n\"\n",
        "        \"FROM `{}` input\\\\n\"\n",
        "        \"LEFT JOIN `{}` output\\\\n\"\n",
        "        \"ON\\\\n\"\n",
        "        \"CAST(input.{} as DATETIME) = CAST(output.{} as DATETIME)\\\\n\"\n",
        "        \"AND CAST(input.{} as STRING) = CAST(output.{} as STRING)\"\n",
        "    )\n",
        "    query = query.format(\n",
        "        time_column,\n",
        "        time_series_identifier_column,\n",
        "        target_column,\n",
        "        target_column,\n",
        "        batch_prediction_bq_input_uri,\n",
        "        batch_prediction_bq_output_uri,\n",
        "        time_column,\n",
        "        time_column,\n",
        "        time_series_identifier_column,\n",
        "        time_series_identifier_column,\n",
        "    )\n",
        "    params = {\n",
        "        \"templateId\": \"067f70d2-8cd6-4a4c-a099-292acd1053e8\",\n",
        "        \"ds0.connector\": \"BIG_QUERY\",\n",
        "        \"ds0.projectId\": PROJECT_ID,\n",
        "        \"ds0.billingProjectId\": PROJECT_ID,\n",
        "        \"ds0.type\": \"CUSTOM_QUERY\",\n",
        "        \"ds0.sql\": query,\n",
        "    }\n",
        "    params_str_parts = []\n",
        "    for k, v in params.items():\n",
        "        params_str_parts.append('\"{}\":\"{}\"'.format(k, v))\n",
        "    params_str = \"\".join([\"{\", \",\".join(params_str_parts), \"}\"])\n",
        "    return \"{}?{}\".format(base_url, urllib.parse.urlencode({\"params\": params_str}))\n",
        "\n",
        "\n",
        "print(\n",
        "    get_data_studio_link(\n",
        "        PREDICTION_DATASET_BQ_PATH,\n",
        "        batch_predict_bq_output_uri,\n",
        "        time_column,\n",
        "        time_series_identifier_column,\n",
        "        target_column,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup:mbsdk"
      },
      "source": [
        "## **Cleaning up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT9A51f1M-a1"
      },
      "outputs": [],
      "source": [
        "# Delete dataset\n",
        "dataset.delete()\n",
        "\n",
        "# Training job\n",
        "training_job.delete()\n",
        "\n",
        "# Delete model\n",
        "model.delete()\n",
        "\n",
        "# Delete batch prediction job\n",
        "batch_prediction_job.delete()\n",
        "\n",
        "# Delete the dataset\n",
        "try:\n",
        "    client.delete_dataset(bq_dataset_id, delete_contents=True, not_found_ok=True)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# Set this to true only if you'd like to delete your bucket\n",
        "delete_bucket = False  # set True for deletion\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gsutil rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tutorial_start:automl"
      ],
      "name": "automl_forecasting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
